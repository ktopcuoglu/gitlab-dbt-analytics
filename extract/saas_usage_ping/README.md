## SaaS Service Ping

SaaS Service Ping (formerly known as "usage ping") is collected from self-installed instances of GitLab for those instances that have the feature enabled. This feature allows GitLab to understand usage data for self-installed instances broken down on an instance and namespace level.

GitLab.com, which is essentially a GitLab-hosted version of GitLab, has sent usage ping data in the past, but this process had problems:
* The service ping process from GitLab.com took too long to run
* Running the same queries in the SaaS instance as other instances resulted in data that was not granular enough. Data was needed from the namespace grain for better analytics.

This extract addresses these issues:  
* This extract offloads the SaaS service ping process to processes in Airflow and Snowflake so it doesn't take production resources to complete.  The queries may still be long-running and costly, but Snowflake is much better suited for large data transformations such as the service ping queries.  Additionally, the data team can monitor durations and costs on this draft dashboard [here](https://app.periscopedata.com/app/gitlab/839683/SaaS-Usage-Ping-Monitoring) to ensure that the costs stay within acceptable bounds. 
* This extract runs queries for the namespace level so that metrics can be gathered in fine enough detail to serve the product and technical account manager teams.

Please review the [public-facing handbook page for SaaS Service Ping](https://about.gitlab.com/handbook/business-technology/data-team/data-catalog/saas-service-ping-automation/) for more information about this process.

### Technical Implementation

The SaaS service pings are generated by iterating through a series of SQL queries and running them in the Snowflake data warehouse. One more kind of data is uploaded - data from `Redis` instance are also uploaded using `RESTful API` technology . The results of the queries are then uploaded into the `saas_usage_ping` schema in the `RAW` Snowflake database.  


- **SQL data** from `Postgres Sql`: The queries are version controlled in the very large JSON files present within this extract.  The queries are split out into two categories: instance queries and namespace queries. The instance queries generate data about GitLab.com as a whole, while the namespace queries generate data about each namespace on GitLab.com.
    - Data is stored in the table: 
        - `"RAW"."SAAS_USAGE_PING"."GITLAB_DOTCOM"`
        - `"RAW"."SAAS_USAGE_PING"."GITLAB_DOTCOM_NAMESPACE"`
- **Redis data**: Data is picked up and stored in a `JSON` format, approximately size is around 2k lines, usually one file per load _(at the moment, it is a weekly load)_. The main purpose of loading data from Redis is to ensure fine granulation of metrics.
    - Data is stored in the table: 
        - `"RAW"."SAAS_USAGE_PING"."INSTANCE_REDIS_METRICS"`
        
### Backfilling SaaS Service Ping

There is also a process in place to recreate SaaS service pings from the past.  There is a separate backfill DAG that allows backfilling service pings for the last 12 months.  The process backfills by filtering the queries to only those that query over a specific timeframe, and then passing in the month it is backfilling for as the timeframe.  As a future iteration, we may add the ability to backfill metrics that do not query just over a specific timeframe (all-time metrics).
